{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1be032",
   "metadata": {},
   "source": [
    "Introduction\n",
    "This notebook is part of a series of notebooks which explore Data Science topics in Python:\n",
    "\n",
    "Bayesian Hyperparameter Tuning in Python\n",
    "Copulas in Python\n",
    "Shapley Values in Python\n",
    "Principle Component Analysis in Python\n",
    "Interest Rate Modelling in Python\n",
    "The purpose of this notebook to to develope an yield curve forecasting model that can be leveraged to predict the rance of interest rate yield curve outlooks across the next 12-months (or more). The methodology outlines in this notebook will leverage dimension reduction techniques and stocastic modelling.\n",
    "\n",
    "Utilizing Principal Component Analysis (PCA) and the Vasicek simulation model proves invaluable in simulating and understanding the complex dynamics of US yield curves. PCA identifies key factors influencing interest rate variations, enabling a more concise representation of yield curve movements. The Vasicek model, incorporating mean reversion, then facilitates the stochastic simulation of future interest rate paths. By integrating PCA-derived principal components into the Vasicek framework, analysts can enhance the granularity of simulations, capturing both systematic factors and the inherent uncertainty in interest rate changes. This combined approach finds applications in risk management, scenario analysis, and portfolio optimization, empowering financial analysts to make more informed decisions by comprehensively simulating the intricate behavior of US yield curves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a79de2",
   "metadata": {},
   "source": [
    "Evironment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3801f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set_style(\"white\")\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Plotly\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly as py\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "### Define the colour scheme\n",
    "c1 = \"#173f5f\"\n",
    "c2 = \"#20639b\"\n",
    "c3 = \"#3caea3\"\n",
    "c4 = \"#f6d55c\"\n",
    "c5 = \"#ed553b\"\n",
    "\n",
    "custom_palette = [c1, c2, c3, c4, c5]\n",
    "sns.palplot(sns.color_palette(custom_palette))\n",
    "\n",
    "# User defined function\n",
    "def summary(df):\n",
    "    summ = pd.DataFrame(df.dtypes, columns=['data type'])\n",
    "    summ['#total'] = df.shape[0]\n",
    "    summ['#missing'] = df.isnull().sum().values \n",
    "    summ['%missing'] = df.isnull().sum().values / len(df)* 100\n",
    "    summ['#unique'] = df.nunique().values\n",
    "    summ['#duplicates'] = summ['#total'] - summ['#unique']\n",
    "    desc = pd.DataFrame(df.describe(include='all').transpose())\n",
    "    summ['min'] = desc['min'].values\n",
    "    summ['max'] = desc['max'].values\n",
    "    return summ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9679045d",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df = pd.read_csv('/kaggle/input/us-yield-curves/yield-curve-rates-1990-2023.csv.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed', dayfirst=False)\n",
    "\n",
    "# Sort by Date\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "# Date as index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# List the variables to keep (<25% missing) and rename\n",
    "keep_vars = ['3 Mo','6 Mo','1 Yr','2 Yr','3 Yr','5 Yr','7 Yr','10 Yr','20 Yr']\n",
    "rename_vars = ['3m','6m','12m','24m','36m','60m','84m','120m','240m']\n",
    "\n",
    "# drop variable and rename\n",
    "df = df[keep_vars]\n",
    "df.columns = rename_vars\n",
    "\n",
    "# Interpolate missing values linearly\n",
    "df = df.interpolate()\n",
    "\n",
    "# Drop rows with missing values still (when missing at beginning or end of time series)\n",
    "df = df.dropna()\n",
    "\n",
    "# View the data\n",
    "summary(df).style.background_gradient(cmap='Blues')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
